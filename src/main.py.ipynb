{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-05T18:19:21.694625Z",
     "start_time": "2025-01-05T18:09:36.323882Z"
    }
   },
   "source": [
    "import time\n",
    "!pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install ultralytics"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\r\n",
      "Collecting torch\r\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torch-2.5.1%2Bcu118-cp310-cp310-linux_x86_64.whl (838.3 MB)\r\n",
      "\u001B[2K     \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m838.3/838.3 MB\u001B[0m \u001B[31m5.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:04\u001B[0m\r\n",
      "\u001B[?25hCollecting torchvision\r\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.20.1%2Bcu118-cp310-cp310-linux_x86_64.whl (6.5 MB)\r\n",
      "\u001B[2K     \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m6.5/6.5 MB\u001B[0m \u001B[31m5.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: filelock in /home/djentci/miniconda3/envs/cv_project/lib/python3.10/site-packages (from torch) (3.13.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/djentci/miniconda3/envs/cv_project/lib/python3.10/site-packages (from torch) (4.12.2)\r\n",
      "Requirement already satisfied: networkx in /home/djentci/miniconda3/envs/cv_project/lib/python3.10/site-packages (from torch) (3.3)\r\n",
      "Requirement already satisfied: jinja2 in /home/djentci/miniconda3/envs/cv_project/lib/python3.10/site-packages (from torch) (3.1.4)\r\n",
      "Requirement already satisfied: fsspec in /home/djentci/miniconda3/envs/cv_project/lib/python3.10/site-packages (from torch) (2024.6.1)\r\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.8.89 (from torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_nvrtc_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (23.2 MB)\r\n",
      "\u001B[2K     \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m23.2/23.2 MB\u001B[0m \u001B[31m5.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting nvidia-cuda-runtime-cu11==11.8.89 (from torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (875 kB)\r\n",
      "\u001B[2K     \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m875.6/875.6 kB\u001B[0m \u001B[31m5.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting nvidia-cuda-cupti-cu11==11.8.87 (from torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux1_x86_64.whl (13.1 MB)\r\n",
      "\u001B[2K     \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m13.1/13.1 MB\u001B[0m \u001B[31m5.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting nvidia-cudnn-cu11==9.1.0.70 (from torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cudnn_cu11-9.1.0.70-py3-none-manylinux2014_x86_64.whl (663.9 MB)\r\n",
      "\u001B[2K     \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m663.9/663.9 MB\u001B[0m \u001B[31m5.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:04\u001B[0m\r\n",
      "\u001B[?25hCollecting nvidia-cublas-cu11==11.11.3.6 (from torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux1_x86_64.whl (417.9 MB)\r\n",
      "\u001B[2K     \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m417.9/417.9 MB\u001B[0m \u001B[31m5.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:02\u001B[0m\r\n",
      "\u001B[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\r\n",
      "\u001B[2K     \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m168.4/168.4 MB\u001B[0m \u001B[31m5.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting nvidia-curand-cu11==10.3.0.86 (from torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_curand_cu11-10.3.0.86-py3-none-manylinux1_x86_64.whl (58.1 MB)\r\n",
      "\u001B[2K     \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m58.1/58.1 MB\u001B[0m \u001B[31m5.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting nvidia-cusolver-cu11==11.4.1.48 (from torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux1_x86_64.whl (128.2 MB)\r\n",
      "\u001B[2K     \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m128.2/128.2 MB\u001B[0m \u001B[31m5.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting nvidia-cusparse-cu11==11.7.5.86 (from torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux1_x86_64.whl (204.1 MB)\r\n",
      "\u001B[2K     \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m204.1/204.1 MB\u001B[0m \u001B[31m5.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:02\u001B[0m\r\n",
      "\u001B[?25hCollecting nvidia-nccl-cu11==2.21.5 (from torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nccl_cu11-2.21.5-py3-none-manylinux2014_x86_64.whl (147.8 MB)\r\n",
      "\u001B[2K     \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m147.8/147.8 MB\u001B[0m \u001B[31m4.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting nvidia-nvtx-cu11==11.8.86 (from torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nvtx_cu11-11.8.86-py3-none-manylinux1_x86_64.whl (99 kB)\r\n",
      "Collecting triton==3.1.0 (from torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\r\n",
      "\u001B[2K     \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m209.5/209.5 MB\u001B[0m \u001B[31m5.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:02\u001B[0m\r\n",
      "\u001B[?25hCollecting sympy==1.13.1 (from torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/sympy-1.13.1-py3-none-any.whl (6.2 MB)\r\n",
      "\u001B[2K     \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m6.2/6.2 MB\u001B[0m \u001B[31m5.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: mpmath<1.4,>=1.1.0 in /home/djentci/miniconda3/envs/cv_project/lib/python3.10/site-packages (from sympy==1.13.1->torch) (1.3.0)\r\n",
      "Requirement already satisfied: numpy in /home/djentci/miniconda3/envs/cv_project/lib/python3.10/site-packages (from torchvision) (1.24.3)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/djentci/miniconda3/envs/cv_project/lib/python3.10/site-packages (from torchvision) (11.0.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/djentci/miniconda3/envs/cv_project/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\r\n",
      "Installing collected packages: triton, sympy, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, torch, torchvision\r\n",
      "  Attempting uninstall: sympy\r\n",
      "    Found existing installation: sympy 1.13.3\r\n",
      "    Uninstalling sympy-1.13.3:\r\n",
      "      Successfully uninstalled sympy-1.13.3\r\n",
      "Successfully installed nvidia-cublas-cu11-11.11.3.6 nvidia-cuda-cupti-cu11-11.8.87 nvidia-cuda-nvrtc-cu11-11.8.89 nvidia-cuda-runtime-cu11-11.8.89 nvidia-cudnn-cu11-9.1.0.70 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.3.0.86 nvidia-cusolver-cu11-11.4.1.48 nvidia-cusparse-cu11-11.7.5.86 nvidia-nccl-cu11-2.21.5 nvidia-nvtx-cu11-11.8.86 sympy-1.13.1 torch-2.5.1+cu118 torchvision-0.20.1+cu118 triton-3.1.0\r\n",
      "Collecting ultralytics\r\n",
      "  Downloading ultralytics-8.3.58-py3-none-any.whl.metadata (35 kB)\r\n",
      "Requirement already satisfied: numpy>=1.23.0 in /home/djentci/miniconda3/envs/cv_project/lib/python3.10/site-packages (from ultralytics) (1.24.3)\r\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /home/djentci/miniconda3/envs/cv_project/lib/python3.10/site-packages (from ultralytics) (3.9.2)\r\n",
      "Collecting opencv-python>=4.6.0 (from ultralytics)\r\n",
      "  Using cached opencv_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\r\n",
      "Requirement already satisfied: pillow>=7.1.2 in /home/djentci/miniconda3/envs/cv_project/lib/python3.10/site-packages (from ultralytics) (11.0.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /home/djentci/miniconda3/envs/cv_project/lib/python3.10/site-packages (from ultralytics) (6.0.2)\r\n",
      "Requirement already satisfied: requests>=2.23.0 in /home/djentci/miniconda3/envs/cv_project/lib/python3.10/site-packages (from ultralytics) (2.32.3)\r\n",
      "Requirement already satisfied: scipy>=1.4.1 in /home/djentci/miniconda3/envs/cv_project/lib/python3.10/site-packages (from ultralytics) (1.10.1)\r\n",
      "Requirement already satisfied: torch>=1.8.0 in /home/djentci/miniconda3/envs/cv_project/lib/python3.10/site-packages (from ultralytics) (2.5.1+cu118)\r\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /home/djentci/miniconda3/envs/cv_project/lib/python3.10/site-packages (from ultralytics) (0.20.1+cu118)\r\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /home/djentci/miniconda3/envs/cv_project/lib/python3.10/site-packages (from ultralytics) (4.66.5)\r\n",
      "Requirement already satisfied: psutil in /home/djentci/miniconda3/envs/cv_project/lib/python3.10/site-packages (from ultralytics) (5.9.0)\r\n",
      "Requirement already satisfied: py-cpuinfo in /home/djentci/miniconda3/envs/cv_project/lib/python3.10/site-packages (from ultralytics) (9.0.0)\r\n",
      "Requirement already satisfied: pandas>=1.1.4 in /home/djentci/miniconda3/envs/cv_project/lib/python3.10/site-packages (from ultralytics) (2.2.3)\r\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /home/djentci/miniconda3/envs/cv_project/lib/python3.10/site-packages (from ultralytics) (0.13.2)\r\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\r\n",
      "  Downloading ultralytics_thop-2.0.13-py3-none-any.whl.metadata (9.4 kB)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/djentci/miniconda3/envs/cv_project/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /home/djentci/miniconda3/envs/cv_project/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (0.11.0)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/djentci/miniconda3/envs/cv_project/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (4.51.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/djentci/miniconda3/envs/cv_project/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /home/djentci/miniconda3/envs/cv_project/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/djentci/miniconda3/envs/cv_project/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/djentci/miniconda3/envs/cv_project/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/djentci/miniconda3/envs/cv_project/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/djentci/miniconda3/envs/cv_project/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/djentci/miniconda3/envs/cv_project/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/djentci/miniconda3/envs/cv_project/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/djentci/miniconda3/envs/cv_project/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2.2.3)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/djentci/miniconda3/envs/cv_project/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2024.12.14)\r\n",
      "Requirement already satisfied: filelock in /home/djentci/miniconda3/envs/cv_project/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/djentci/miniconda3/envs/cv_project/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\r\n",
      "Requirement already satisfied: networkx in /home/djentci/miniconda3/envs/cv_project/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.3)\r\n",
      "Requirement already satisfied: jinja2 in /home/djentci/miniconda3/envs/cv_project/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\r\n",
      "Requirement already satisfied: fsspec in /home/djentci/miniconda3/envs/cv_project/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /home/djentci/miniconda3/envs/cv_project/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (11.8.89)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /home/djentci/miniconda3/envs/cv_project/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (11.8.89)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /home/djentci/miniconda3/envs/cv_project/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (11.8.87)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /home/djentci/miniconda3/envs/cv_project/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /home/djentci/miniconda3/envs/cv_project/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (11.11.3.6)\r\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/djentci/miniconda3/envs/cv_project/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (10.9.0.58)\r\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /home/djentci/miniconda3/envs/cv_project/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (10.3.0.86)\r\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /home/djentci/miniconda3/envs/cv_project/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (11.4.1.48)\r\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /home/djentci/miniconda3/envs/cv_project/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (11.7.5.86)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.21.5 in /home/djentci/miniconda3/envs/cv_project/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2.21.5)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /home/djentci/miniconda3/envs/cv_project/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (11.8.86)\r\n",
      "Requirement already satisfied: triton==3.1.0 in /home/djentci/miniconda3/envs/cv_project/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.1.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/djentci/miniconda3/envs/cv_project/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/djentci/miniconda3/envs/cv_project/lib/python3.10/site-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /home/djentci/miniconda3/envs/cv_project/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/djentci/miniconda3/envs/cv_project/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\r\n",
      "Downloading ultralytics-8.3.58-py3-none-any.whl (905 kB)\r\n",
      "\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m905.3/905.3 kB\u001B[0m \u001B[31m4.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hUsing cached opencv_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (62.5 MB)\r\n",
      "Downloading ultralytics_thop-2.0.13-py3-none-any.whl (26 kB)\r\n",
      "Installing collected packages: opencv-python, ultralytics-thop, ultralytics\r\n",
      "Successfully installed opencv-python-4.10.0.84 ultralytics-8.3.58 ultralytics-thop-2.0.13\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T20:13:44.953069Z",
     "start_time": "2025-01-08T20:13:41.757187Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import cv2\n",
    "import xml.etree.ElementTree as ET\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import yaml\n",
    "from shutil import copyfile\n",
    "from ultralytics import YOLO\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import average_precision_score\n",
    "import numpy as np"
   ],
   "id": "83afb22c940793af",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T20:13:44.957722Z",
     "start_time": "2025-01-08T20:13:44.954380Z"
    }
   },
   "cell_type": "code",
   "source": [
    "base_path = \"../resources/dataset\"\n",
    "annotations_path = os.path.join(base_path, \"annotations\")\n",
    "images_path = os.path.join(base_path, \"images\")\n",
    "train_output_path = \"../resources/yolo_train\"\n",
    "test_output_path = \"../resources/yolo_test\"\n",
    "model_output_path = \"../resources/yolo_model\"\n",
    "yaml_config_path = \"yolo_config.yaml\""
   ],
   "id": "c0cf258bfb6f1299",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T20:23:01.298521Z",
     "start_time": "2025-01-08T20:23:01.291828Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def split_dataset(images_path, annotations_path, train_output_path, test_output_path, test_ratio=0.2, seed=42):\n",
    "    \"\"\"\n",
    "    Splits a dataset of images and annotations into training and testing sets.\n",
    "\n",
    "    Parameters:\n",
    "        images_path (str): Path to the folder containing image files.\n",
    "        annotations_path (str): Path to the folder containing annotation files.\n",
    "        train_output_path (str): Path to save the training set.\n",
    "        test_output_path (str): Path to save the testing set.\n",
    "        test_ratio (float): Ratio of the dataset to be used for testing. Default is 0.2.\n",
    "        seed (int): Random seed for reproducibility. Default is 42.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Collect valid image files that have corresponding annotation files\n",
    "    image_files = [\n",
    "        f for f in os.listdir(images_path)\n",
    "        if f.endswith(('.png', '.jpg', '.jpeg')) and os.path.exists(\n",
    "            os.path.join(annotations_path, os.path.splitext(f)[0] + '.xml')\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Shuffle files with a fixed random seed\n",
    "    random.seed(seed)\n",
    "    random.shuffle(image_files)\n",
    "\n",
    "    # Calculate the split\n",
    "    test_count = int(len(image_files) * test_ratio)\n",
    "    test_files = image_files[:test_count]\n",
    "    train_files = image_files[test_count:]\n",
    "\n",
    "    # Ensure output directories exist\n",
    "    for folder in [train_output_path, test_output_path]:\n",
    "        os.makedirs(os.path.join(folder, \"images\"), exist_ok=True)\n",
    "        os.makedirs(os.path.join(folder, \"labels\"), exist_ok=True)\n",
    "\n",
    "    # Helper function to copy files\n",
    "    def copy_files(file_list, output_path):\n",
    "        for image_file in file_list:\n",
    "            annotation_file = os.path.splitext(image_file)[0] + '.xml'\n",
    "            image_src = os.path.join(images_path, image_file)\n",
    "            annotation_src = os.path.join(annotations_path, annotation_file)\n",
    "\n",
    "            if os.path.exists(annotation_src):\n",
    "                copyfile(image_src, os.path.join(output_path, \"images\", image_file))\n",
    "                copyfile(annotation_src, os.path.join(output_path, \"labels\", annotation_file))\n",
    "            else:\n",
    "                print(f\"Warning: Missing annotation for {image_file}. Skipping.\")\n",
    "\n",
    "    # Copy files to train and test directories\n",
    "    copy_files(train_files, train_output_path)\n",
    "    copy_files(test_files, test_output_path)\n",
    "\n",
    "    # Log the results\n",
    "    print(f\"Dataset split completed.\")\n",
    "    print(f\"Train set: {len(train_files)} images\")\n",
    "    print(f\"Test set: {len(test_files)} images\")"
   ],
   "id": "43b11dad3cc18310",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T20:13:48.766958Z",
     "start_time": "2025-01-08T20:13:48.761491Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def prepare_yolo_dataset(annotations_path, output_path):\n",
    "    labels_path = os.path.join(output_path, \"labels\")\n",
    "    images_path = os.path.join(output_path, \"images\")\n",
    "\n",
    "    for annotation_file in os.listdir(labels_path):\n",
    "        if annotation_file.endswith(\".xml\"):\n",
    "            annotation_path = os.path.join(labels_path, annotation_file)\n",
    "\n",
    "            tree = ET.parse(annotation_path)\n",
    "            root = tree.getroot()\n",
    "\n",
    "            # Extract image size\n",
    "            size = root.find(\"size\")\n",
    "            image_width = int(size.find(\"width\").text)\n",
    "            image_height = int(size.find(\"height\").text)\n",
    "\n",
    "            # Create YOLO format labels\n",
    "            label_file = os.path.join(labels_path, annotation_file.replace(\".xml\", \".txt\"))\n",
    "            with open(label_file, 'w') as label_out:\n",
    "                for obj in root.findall(\"object\"):\n",
    "                    class_name = obj.find(\"name\").text\n",
    "                    class_id = 0 if class_name == \"without_mask\" else 1  # Map class names to IDs\n",
    "\n",
    "                    bndbox = obj.find(\"bndbox\")\n",
    "                    xmin = int(bndbox.find(\"xmin\").text)\n",
    "                    ymin = int(bndbox.find(\"ymin\").text)\n",
    "                    xmax = int(bndbox.find(\"xmax\").text)\n",
    "                    ymax = int(bndbox.find(\"ymax\").text)\n",
    "\n",
    "                    x_center = ((xmin + xmax) / 2) / image_width\n",
    "                    y_center = ((ymin + ymax) / 2) / image_height\n",
    "                    width = (xmax - xmin) / image_width\n",
    "                    height = (ymax - ymin) / image_height\n",
    "\n",
    "                    label_out.write(f\"{class_id} {x_center} {y_center} {width} {height}\\n\")"
   ],
   "id": "d1a6d90ece3396f3",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T20:13:50.612286Z",
     "start_time": "2025-01-08T20:13:50.609114Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_yaml_config(train_path, test_path):\n",
    "    config = {\n",
    "        'train': os.path.abspath(os.path.join(train_path, 'images')),\n",
    "        'val': os.path.abspath(os.path.join(test_path, 'images')),\n",
    "        'nc': 2,  # Number of classes\n",
    "        'names': ['without_mask', 'with_mask']  # Class names\n",
    "    }\n",
    "    with open(yaml_config_path, 'w') as yaml_file:\n",
    "        yaml.dump(config, yaml_file)\n",
    "    return yaml_config_path"
   ],
   "id": "e52585d476bdce76",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T20:13:51.175854Z",
     "start_time": "2025-01-08T20:13:51.171559Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_yolo_model(train_path, test_path, epochs=80, batch_size=16):\n",
    "    model = YOLO(\"yolov8n.pt\")  # Load a pre-trained YOLO model (YOLOv8 Nano as an example)\n",
    "\n",
    "    # Generate YAML config file\n",
    "    data_config_path = generate_yaml_config(train_path, test_path)\n",
    "\n",
    "    # Ensure the YAML file is created using exponential backoff\n",
    "    delay = 1  # Initial delay in seconds\n",
    "    max_retries = 10\n",
    "    for attempt in range(max_retries):\n",
    "        if os.path.exists(data_config_path):\n",
    "            break\n",
    "        print(f\"YAML file not found. Retrying in {delay} seconds...\")\n",
    "        time.sleep(delay)\n",
    "        delay *= 2  # Double the delay for exponential backoff\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"YAML configuration file '{data_config_path}' was not created after {max_retries} attempts.\")\n",
    "\n",
    "    # Define training configuration\n",
    "    model.train(\n",
    "        data=data_config_path,\n",
    "        epochs=epochs,\n",
    "        batch=batch_size,  # Correct parameter name\n",
    "        project=model_output_path,\n",
    "        name=\"yolo_training\",\n",
    "        exist_ok=True\n",
    "    )\n"
   ],
   "id": "f6f0043a476eb4fb",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T20:13:52.057832Z",
     "start_time": "2025-01-08T20:13:52.054084Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_iou(box1, box2):\n",
    "    \"\"\"\n",
    "    Calculate the Intersection over Union (IoU) of two boxes.\n",
    "    :param box1: [x1, y1, x2, y2]\n",
    "    :param box2: [x1, y1, x2, y2]\n",
    "    :return: IoU value\n",
    "    \"\"\"\n",
    "    x1 = max(box1[0], box2[0])\n",
    "    y1 = max(box1[1], box2[1])\n",
    "    x2 = min(box1[2], box2[2])\n",
    "    y2 = min(box1[3], box2[3])\n",
    "\n",
    "    # Calculate intersection area\n",
    "    intersection = max(0, x2 - x1) * max(0, y2 - y1)\n",
    "\n",
    "    # Calculate areas of the boxes\n",
    "    area_box1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "    area_box2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "\n",
    "    # Calculate union area\n",
    "    union = area_box1 + area_box2 - intersection\n",
    "\n",
    "    # IoU\n",
    "    return intersection / union if union > 0 else 0"
   ],
   "id": "84f8869935bb9506",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T20:47:14.172896Z",
     "start_time": "2025-01-08T20:47:14.165315Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_yolo_model_metrics(model_path, test_images_path, ground_truth_boxes_dict):\n",
    "    model = YOLO(model_path)  # Load the trained YOLO model\n",
    "\n",
    "    y_true = []  # True labels\n",
    "    y_pred = []  # Predicted labels\n",
    "    iou_scores = []  # List to store IoU scores\n",
    "    conf_scores = []  # List to store confidence scores\n",
    "\n",
    "    for image_file in os.listdir(test_images_path):\n",
    "        if image_file.endswith(('.png', '.jpg', '.jpeg')):\n",
    "            image_path = os.path.join(test_images_path, image_file)\n",
    "\n",
    "            # Skip images with no ground truth\n",
    "            if image_file not in ground_truth_boxes_dict:\n",
    "                print(f\"Warning: No ground truth for {image_file}. Skipping...\")\n",
    "                continue\n",
    "\n",
    "            results = model.predict(source=image_path, save=False)\n",
    "\n",
    "            # Get predicted boxes\n",
    "            predicted_boxes = results[0].boxes.xyxy.cpu().numpy() if results[0].boxes.xyxy is not None else []\n",
    "            predicted_classes = results[0].boxes.cls.cpu().numpy() if results[0].boxes.cls is not None else []\n",
    "            predicted_confidences = results[0].boxes.conf.cpu().numpy() if results[0].boxes.conf is not None else []\n",
    "            ground_truth_boxes = ground_truth_boxes_dict.get(image_file, [])  # Ground truth boxes\n",
    "\n",
    "            # Check for mismatch\n",
    "            if len(ground_truth_boxes) != len(predicted_boxes):\n",
    "                print(f\"Skipping {image_file}: Ground Truths={len(ground_truth_boxes)}, Predictions={len(predicted_boxes)}\")\n",
    "                continue\n",
    "\n",
    "            # Add ground truth classes\n",
    "            y_true.extend([gt_box[4] for gt_box in ground_truth_boxes])\n",
    "\n",
    "            # Add predictions to y_pred\n",
    "            for pred_class, pred_conf in zip(predicted_classes, predicted_confidences):\n",
    "                y_pred.append(pred_class)\n",
    "                conf_scores.append(pred_conf)\n",
    "\n",
    "            # Debugging output\n",
    "            print(f\"Processed {image_file}: Ground Truths={len(ground_truth_boxes)}, Predictions={len(predicted_boxes)}\")\n",
    "\n",
    "    # Calculate metrics only if there are valid samples\n",
    "    if not y_true or not y_pred:\n",
    "        raise ValueError(\"No valid samples for evaluation. Check your data and model predictions.\")\n",
    "\n",
    "    # Calculate metrics\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted', zero_division=1)\n",
    "    mean_iou = np.mean(iou_scores) if iou_scores else 0\n",
    "    mean_conf = np.mean(conf_scores) if conf_scores else 0\n",
    "\n",
    "    # Print metrics\n",
    "    print(\"\\nEvaluation Metrics:\")\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"F1 Score: {f1:.2f}\")\n",
    "    print(f\"Mean IoU: {mean_iou:.2f}\")\n",
    "    print(f\"Mean Confidence: {mean_conf:.2f}\")\n"
   ],
   "id": "327dc6a5d8296088",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T20:23:13.785283Z",
     "start_time": "2025-01-08T20:23:12.613465Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess_data():\n",
    "    print(\"Splitting dataset into training and testing sets...\")\n",
    "    split_dataset(images_path, annotations_path, train_output_path, test_output_path)\n",
    "\n",
    "    print(\"Preparing YOLO datasets...\")\n",
    "    prepare_yolo_dataset(annotations_path, train_output_path)\n",
    "    prepare_yolo_dataset(annotations_path, test_output_path)\n",
    "    \n",
    "    \n",
    "\n",
    "# Run the main function\n",
    "preprocess_data()"
   ],
   "id": "cd148cd0f93ac42b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting dataset into training and testing sets...\n",
      "Dataset split completed.\n",
      "Train set: 683 images\n",
      "Test set: 170 images\n",
      "Preparing YOLO datasets...\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T20:43:53.103925Z",
     "start_time": "2025-01-08T20:34:25.519212Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_model_and_eval():\n",
    "    print(\"Training YOLO model...\")\n",
    "    train_yolo_model(train_output_path, test_output_path, epochs=80, batch_size=16)\n",
    "\n",
    "    print(\"Evaluating YOLO model metrics...\")\n",
    "    evaluate_yolo_model_metrics(os.path.join(model_output_path, \"yolo_training/weights/best.pt\"), os.path.join(test_output_path, \"images\"))\n",
    "\n",
    "\n",
    "    print(\"YOLO training and evaluation completed.\")\n",
    "train_model_and_eval()"
   ],
   "id": "4cd785f4f2b6fefd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training YOLO model...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.25M/6.25M [00:01<00:00, 4.96MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.58 ğŸš€ Python-3.10.0 torch-2.5.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 5938MiB)\n",
      "\u001B[34m\u001B[1mengine/trainer: \u001B[0mtask=detect, mode=train, model=yolov8n.pt, data=yolo_config.yaml, epochs=80, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=../resources/yolo_model, name=yolo_training, exist_ok=True, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=../resources/yolo_model/yolo_training\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751702  ultralytics.nn.modules.head.Detect           [2, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3,011,238 parameters, 3,011,222 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001B[34m\u001B[1mAMP: \u001B[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.35M/5.35M [00:01<00:00, 5.21MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mAMP: \u001B[0mchecks passed âœ…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning /home/djentci/Desktop/comp_vision_project/resources/yolo_train/labels... 683 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 683/683 [00:00<00:00, 1041.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mtrain: \u001B[0mNew cache created: /home/djentci/Desktop/comp_vision_project/resources/yolo_train/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning /home/djentci/Desktop/comp_vision_project/resources/yolo_test/labels... 170 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 170/170 [00:00<00:00, 521.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mval: \u001B[0mNew cache created: /home/djentci/Desktop/comp_vision_project/resources/yolo_test/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to ../resources/yolo_model/yolo_training/labels.jpg... \n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001B[1m../resources/yolo_model/yolo_training\u001B[0m\n",
      "Starting training for 80 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/80      2.22G      2.139      3.674       1.71        123        640:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 17/43 [00:02<00:03,  7.14it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
      "       1/80      2.23G      1.826      2.845      1.461        119        640:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 31/43 [00:04<00:01,  7.66it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
      "       1/80      2.33G      1.692      2.476      1.361         60        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:06<00:00,  6.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  6.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933      0.014      0.669      0.283      0.172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/80      2.62G      1.316      1.315      1.068         88        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  7.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933      0.614      0.386      0.462      0.279\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/80      2.25G      1.332      1.073      1.066        153        640:   5%|â–         | 2/43 [00:00<00:05,  7.45it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
      "       3/80      2.37G      1.282       1.12      1.067         58        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  7.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933      0.772      0.632      0.702      0.423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/80      2.52G      1.246      1.034      1.064        129        640:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 38/43 [00:04<00:00,  7.59it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
      "       4/80      2.52G       1.25      1.026      1.064        132        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  7.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933      0.786      0.676      0.743      0.437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/80      2.74G      1.227     0.9479      1.047         60        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  7.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933      0.785      0.686      0.733      0.459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/80      2.22G      1.172     0.9391      1.039        168        640:   5%|â–         | 2/43 [00:00<00:05,  7.91it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
      "       6/80      2.67G      1.183     0.8951      1.032         52        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  8.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933      0.835      0.724      0.809      0.489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/80      2.19G      1.201     0.8304     0.9668        153        640:   2%|â–         | 1/43 [00:00<00:05,  7.91it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
      "       7/80      2.44G      1.162     0.8427      1.033         74        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  8.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933      0.858      0.735      0.839      0.508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/80      2.17G      1.197     0.8154      1.015        136        640:   5%|â–         | 2/43 [00:00<00:05,  7.55it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
      "       8/80      2.53G      1.178     0.8121      1.026        107        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  8.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933      0.905      0.676      0.802      0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/80      2.19G      1.082     0.7965      1.043         66        640:  14%|â–ˆâ–        | 6/43 [00:00<00:04,  7.58it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
      "       9/80      2.54G      1.154      0.795      1.016        100        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  7.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933      0.857      0.723      0.822      0.506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/80      2.82G      1.216     0.8138      1.011         93        640:  14%|â–ˆâ–        | 6/43 [00:00<00:04,  7.50it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
      "      10/80      2.82G      1.141     0.7543      1.005        103        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  7.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933      0.822      0.735      0.825      0.504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/80      2.77G      1.131     0.7443      1.016        116        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:06<00:00,  7.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  7.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933      0.841      0.777      0.848      0.523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/43 [00:00<?, ?it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
      "      12/80      2.64G      1.109     0.7127      1.011         54        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  8.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933      0.835       0.81      0.865      0.539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/80      2.52G      1.082      0.685      0.997        104        640:  33%|â–ˆâ–ˆâ–ˆâ–      | 14/43 [00:01<00:03,  7.36it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
      "      13/80      2.78G      1.086     0.6945     0.9985        112        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  6.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933       0.87      0.753       0.84       0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/80      2.68G      1.142      0.708      1.007         94        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  8.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933      0.861      0.771      0.847      0.541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/80      2.56G      1.115      0.708     0.9904        210        640:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 18/43 [00:02<00:03,  7.49it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
      "      15/80      2.56G      1.121     0.7045     0.9933        104        640:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 31/43 [00:04<00:01,  7.69it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
      "      15/80      2.56G      1.125     0.7012     0.9948        143        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  8.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933      0.855      0.815      0.868      0.541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/80      2.67G      1.098     0.6713      1.002         71        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  8.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933      0.875       0.81      0.865      0.535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/80       2.3G      1.159     0.6479     0.9996        150        640:  12%|â–ˆâ–        | 5/43 [00:00<00:05,  7.58it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
      "      17/80      2.59G      1.087     0.6473     0.9959         84        640:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 40/43 [00:05<00:00,  7.56it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
      "      17/80      2.59G      1.085     0.6482     0.9965         95        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  8.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933      0.919      0.734      0.864      0.557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/80       2.8G      1.091      0.647     0.9882         85        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  8.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933       0.89      0.794      0.874      0.545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/80      2.23G      1.066     0.6321     0.9844        116        640:  26%|â–ˆâ–ˆâ–Œ       | 11/43 [00:01<00:04,  7.71it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
      "      19/80      2.34G      1.067     0.6453     0.9908         54        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  8.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933      0.885      0.784      0.872      0.551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/80      2.93G      1.079     0.6204      0.987        107        640:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 40/43 [00:05<00:00,  7.51it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
      "      20/80      2.93G      1.071     0.6199     0.9866         81        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  8.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933      0.861      0.793      0.876       0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/80      2.62G      1.063     0.6263      0.999         52        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  8.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933      0.864      0.764      0.852      0.546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/80      2.34G      1.041     0.6068     0.9746        200        640:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 26/43 [00:03<00:02,  7.71it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
      "      22/80      2.64G      1.049     0.6133     0.9793         98        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  8.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933      0.868      0.811      0.871      0.549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/80      2.88G      1.055     0.6231     0.9774        103        640:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19/43 [00:02<00:03,  7.63it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
      "      23/80      2.88G      1.058     0.6244      0.978         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  8.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933      0.855      0.794      0.883      0.565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/80      2.26G      1.047     0.5979     0.9795         73        640:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 22/43 [00:02<00:02,  7.55it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
      "      24/80      2.37G      1.046     0.6046     0.9809         91        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  7.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933      0.852       0.83      0.888      0.571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/80      2.95G       1.06     0.5998     0.9747         63        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:06<00:00,  7.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  8.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933       0.91      0.784      0.881      0.551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/80      2.77G      1.053     0.6063     0.9675        137        640:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 17/43 [00:02<00:03,  7.65it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
      "      26/80      2.77G      1.034     0.5987     0.9707         96        640:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 40/43 [00:05<00:00,  7.50it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
      "      26/80      2.77G      1.032     0.6002     0.9703        145        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  8.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933      0.895      0.803      0.876      0.558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/80      2.41G      1.031      0.591     0.9741         96        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  8.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933      0.868      0.801      0.866      0.551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/80      2.33G      1.009     0.5709     0.9685        160        640:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 33/43 [00:04<00:01,  7.39it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
      "      28/80      2.33G       1.01     0.5664     0.9686        118        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  8.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933      0.866      0.806      0.864      0.553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/80      2.69G      1.038     0.5767     0.9693        171        640:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 40/43 [00:05<00:00,  7.52it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
      "      29/80      2.69G      1.034     0.5767     0.9693        110        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  8.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933      0.865        0.8      0.868      0.571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/80      2.35G      1.021     0.5576     0.9654        116        640:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 38/43 [00:05<00:00,  7.72it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
      "      30/80      2.35G      1.016     0.5559     0.9663         82        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  8.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933      0.854      0.806      0.877      0.564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      31/80      3.02G      1.008     0.5668     0.9611        104        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  8.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933      0.893      0.794      0.877       0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      32/80      2.19G      1.029     0.5699     0.9559        203        640:  33%|â–ˆâ–ˆâ–ˆâ–      | 14/43 [00:01<00:03,  7.57it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
      "      32/80      2.69G      1.025     0.5634     0.9575        336        640:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 29/43 [00:03<00:01,  7.14it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
      "      32/80       2.7G      1.013     0.5592      0.955         92        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  8.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933      0.893      0.803      0.885      0.577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      33/80      2.42G     0.9886     0.5507       0.95        159        640:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 33/43 [00:04<00:01,  7.64it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
      "      33/80      2.42G     0.9923     0.5497      0.955         58        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  8.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933      0.894      0.807      0.885      0.563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      34/80      2.75G      1.002     0.5438      0.959         56        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  8.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933      0.892      0.831      0.897      0.576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      35/80      2.19G      0.993     0.5667     0.9612        149        640:  14%|â–ˆâ–        | 6/43 [00:00<00:04,  7.61it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
      "      35/80      2.72G     0.9943     0.5443     0.9543         79        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  8.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933      0.914       0.82      0.897      0.579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      36/80      2.64G     0.9918     0.5395      0.959        186        640:  28%|â–ˆâ–ˆâ–Š       | 12/43 [00:01<00:04,  7.54it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
      "      36/80      2.65G     0.9763     0.5332      0.959         72        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  8.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933      0.928      0.803      0.895      0.591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/43 [00:00<?, ?it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
      "      37/80      2.82G      0.986     0.5413     0.9423         84        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  8.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933      0.895      0.816      0.895      0.576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      38/80      2.31G     0.9876     0.5502     0.9732         92        640:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 16/43 [00:02<00:03,  7.45it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
      "      38/80      3.09G     0.9836      0.542     0.9611         62        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  8.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933      0.902       0.82      0.887      0.565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      39/80      2.76G     0.9736     0.5175     0.9534         82        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  8.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933      0.873      0.827      0.892      0.574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      40/80      2.32G     0.9689     0.5086     0.9509         95        640:  28%|â–ˆâ–ˆâ–Š       | 12/43 [00:01<00:04,  7.68it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
      "      40/80      2.81G     0.9709     0.5194     0.9509        101        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  8.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933      0.891      0.821      0.893      0.583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      41/80      2.63G     0.9973     0.5173     0.9572        121        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  8.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933      0.891      0.819      0.894      0.577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      42/80       2.2G     0.9688     0.5305     0.9599         80        640:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 21/43 [00:02<00:02,  7.72it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
      "      42/80      2.74G     0.9704     0.5251     0.9589         56        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  8.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933       0.86      0.839      0.891      0.585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      43/80      2.86G     0.9584     0.5227     0.9417        121        640:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 38/43 [00:05<00:00,  7.54it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
      "      43/80      2.86G     0.9572     0.5215     0.9393        140        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  8.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933      0.915      0.829      0.914       0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      44/80      2.38G     0.9428     0.5011     0.9462         64        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  8.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933      0.896      0.818      0.895      0.579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      45/80      2.35G     0.9406     0.5154     0.9361         57        640:  28%|â–ˆâ–ˆâ–Š       | 12/43 [00:01<00:04,  7.61it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
      "      45/80      2.48G     0.9307     0.5009     0.9405         71        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  8.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933      0.847      0.844      0.898      0.576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      46/80      2.44G     0.9663     0.5167     0.9512         98        640:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 26/43 [00:03<00:02,  7.73it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
      "      46/80       2.6G     0.9568     0.5084     0.9467         77        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  8.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933      0.869      0.817      0.897      0.582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      47/80      2.21G     0.9578     0.5057     0.9376        117        640:  14%|â–ˆâ–        | 6/43 [00:00<00:04,  7.69it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
      "      47/80       2.5G     0.9481     0.5061     0.9461         66        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  7.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933      0.923      0.797      0.899      0.588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      48/80      2.48G     0.9606      0.494     0.9218        182        640:  12%|â–ˆâ–        | 5/43 [00:00<00:05,  7.16it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
      "      48/80      2.48G     0.9294     0.4889     0.9338        175        640:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 34/43 [00:04<00:01,  7.50it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
      "      48/80      2.48G     0.9375     0.4906     0.9395         67        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  8.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933      0.881       0.84      0.909      0.578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      49/80       2.4G     0.9449     0.4895     0.9353         63        640:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 38/43 [00:05<00:00,  7.42it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
      "      49/80       2.4G     0.9412     0.4877     0.9344         75        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  8.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933      0.866      0.816      0.889      0.576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      50/80      2.48G     0.9482      0.504     0.9455        132        640:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 41/43 [00:05<00:00,  7.50it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
      "      50/80      2.48G     0.9457     0.5024     0.9448         58        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  8.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933      0.852      0.832        0.9      0.583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      51/80      2.76G     0.9349     0.4923     0.9296        109        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  8.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933      0.885       0.82      0.905      0.596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      52/80      2.32G     0.9282     0.4833     0.9263        139        640:  33%|â–ˆâ–ˆâ–ˆâ–      | 14/43 [00:01<00:03,  7.57it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
      "      52/80      2.48G     0.9324     0.4857     0.9335        132        640:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 39/43 [00:05<00:00,  7.58it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
      "      52/80      2.48G     0.9346     0.4859     0.9343        103        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  7.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933       0.87      0.817      0.893       0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      53/80      2.18G     0.9046     0.4772     0.9335        104        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  8.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933      0.902      0.754      0.882      0.581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      54/80      2.53G     0.9373     0.4859     0.9329        186        640:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 18/43 [00:02<00:03,  7.47it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
      "      54/80      3.07G     0.9226     0.4819     0.9302         47        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  8.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933      0.907      0.813      0.894      0.583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      55/80      2.86G      0.925     0.4728     0.9261         72        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  8.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933      0.879      0.855      0.903      0.593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      56/80      2.19G     0.8652      0.455     0.9208        152        640:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 18/43 [00:02<00:03,  7.54it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
      "      56/80      2.43G      0.889     0.4591     0.9252         92        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  8.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933      0.908      0.821      0.911        0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      57/80      2.68G     0.8927     0.4535     0.9226        115        640:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19/43 [00:02<00:03,  7.61it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
      "      57/80      2.68G     0.8991       0.46     0.9259        162        640:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 35/43 [00:04<00:01,  7.55it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
      "      57/80      3.08G     0.9057     0.4634     0.9251         91        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  8.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933      0.897      0.811        0.9      0.593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      58/80      2.67G     0.8896     0.4664     0.9281        119        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  8.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933      0.898      0.797      0.897      0.589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      59/80      3.21G     0.8805     0.4487     0.9185        130        640:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 21/43 [00:02<00:02,  7.62it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
      "      59/80      3.21G     0.8934     0.4548     0.9195        119        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  8.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933      0.887      0.822      0.896      0.587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      60/80      2.21G     0.9077     0.4802     0.9216        114        640:  23%|â–ˆâ–ˆâ–       | 10/43 [00:01<00:04,  7.53it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
      "      60/80      2.34G     0.9004     0.4712     0.9263        162        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  8.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933      0.872      0.851      0.908      0.597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      61/80      2.23G     0.8395     0.4475     0.9179        140        640:  12%|â–ˆâ–        | 5/43 [00:00<00:04,  7.67it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
      "      61/80      2.81G      0.861     0.4489     0.9107         91        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  8.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933      0.869      0.858      0.911      0.593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      62/80      2.21G     0.8244     0.4383     0.9021        140        640:  16%|â–ˆâ–‹        | 7/43 [00:00<00:04,  7.40it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
      "      62/80      2.34G     0.8555     0.4478     0.9191         89        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/6 [00:00<?, ?it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  8.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933      0.899      0.814      0.901      0.595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      63/80      2.91G     0.8581     0.4345     0.9094        137        640:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 39/43 [00:05<00:00,  7.62it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
      "      63/80      2.92G     0.8551      0.433     0.9106         71        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  8.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933      0.899      0.832      0.907      0.593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      64/80      2.44G     0.8562     0.4356     0.9128         78        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  8.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933      0.913      0.816      0.902      0.592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      65/80      2.16G      0.804     0.4125     0.9028         97        640:   9%|â–‰         | 4/43 [00:00<00:05,  7.77it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
      "      65/80      2.43G     0.8785     0.4468     0.9107        192        640:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 30/43 [00:04<00:01,  7.34it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
      "      65/80      2.43G     0.8679     0.4437     0.9113         65        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  8.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933      0.921      0.821      0.904      0.593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      66/80      2.45G     0.8758     0.4455     0.9164         69        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  8.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933       0.87      0.863      0.909      0.598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      67/80      2.31G     0.8328     0.4193     0.9049         84        640:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 17/43 [00:02<00:03,  7.58it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
      "      67/80      2.31G     0.8451     0.4242     0.9075        138        640:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 29/43 [00:03<00:01,  7.61it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
      "      67/80      2.44G     0.8429     0.4249      0.907         63        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  8.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933      0.872      0.868       0.91      0.599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      68/80      2.23G     0.8377     0.4253     0.9126        103        640:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 28/43 [00:03<00:01,  7.70it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
      "      68/80      2.35G     0.8435     0.4272     0.9141         80        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  8.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933      0.921       0.83       0.91      0.597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      69/80      2.99G      0.843     0.4281     0.9077        101        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  8.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933      0.896      0.847       0.91      0.593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      70/80      2.48G     0.8621     0.4314     0.9077        135        640:  19%|â–ˆâ–Š        | 8/43 [00:01<00:04,  7.57it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
      "      70/80      2.48G     0.8396     0.4218     0.8996         47        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/6 [00:00<?, ?it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  8.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933      0.893      0.832      0.908      0.592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/43 [00:00<?, ?it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
      "      71/80      2.86G     0.8185      0.396     0.8933         46        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:06<00:00,  7.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  8.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933       0.89      0.842      0.902      0.588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      72/80      2.64G     0.8062     0.3907     0.8879         64        640:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 27/43 [00:03<00:02,  7.63it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
      "      72/80      2.64G     0.7996     0.3837     0.8859         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  8.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933      0.884       0.84      0.906      0.596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      73/80      2.17G      0.784     0.3879     0.8759         45        640:  35%|â–ˆâ–ˆâ–ˆâ–      | 15/43 [00:01<00:03,  7.71it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
      "      73/80      2.49G      0.808     0.3852     0.8862        142        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  8.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933      0.897      0.856      0.915      0.596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      74/80      2.14G     0.8074     0.3868     0.8826         66        640:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 25/43 [00:03<00:02,  7.71it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
      "      74/80      2.68G     0.7996     0.3816     0.8805         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  8.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933      0.912       0.84      0.913      0.595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      75/80      2.68G     0.7939     0.3828     0.8905         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  8.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933      0.901      0.836      0.914      0.594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      76/80      2.78G     0.7834     0.3732     0.8806         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  8.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933      0.897      0.844      0.911      0.596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/43 [00:00<?, ?it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
      "      77/80      2.79G     0.7803     0.3725     0.8835         54        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  8.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933      0.907      0.842      0.911      0.598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      78/80      2.18G     0.7255     0.3489      0.889         54        640:   9%|â–‰         | 4/43 [00:00<00:05,  7.63it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
      "      78/80      2.68G     0.7872     0.3787     0.8834         57        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  8.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933      0.897      0.838      0.909      0.593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      79/80      2.71G     0.7702     0.3671     0.8804         53        640:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 39/43 [00:05<00:00,  7.74it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
      "      79/80      2.71G     0.7707     0.3684     0.8814         58        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  8.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933      0.902      0.839      0.913      0.595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      80/80      2.43G     0.7682      0.368     0.8803         52        640:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 37/43 [00:04<00:00,  7.57it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
      "      80/80      2.43G     0.7694     0.3698     0.8809         65        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  7.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  8.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933      0.894      0.844      0.912      0.598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "80 epochs completed in 0.153 hours.\n",
      "Optimizer stripped from ../resources/yolo_model/yolo_training/weights/last.pt, 6.2MB\n",
      "Optimizer stripped from ../resources/yolo_model/yolo_training/weights/best.pt, 6.2MB\n",
      "\n",
      "Validating ../resources/yolo_model/yolo_training/weights/best.pt...\n",
      "Ultralytics 8.3.58 ğŸš€ Python-3.10.0 torch-2.5.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 5938MiB)\n",
      "Model summary (fused): 168 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        170        933      0.903      0.825      0.911        0.6\n",
      "          without_mask         56        192      0.859      0.734      0.859      0.531\n",
      "             with_mask        164        741      0.947      0.915      0.963       0.67\n",
      "Speed: 0.3ms preprocess, 1.6ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Results saved to \u001B[1m../resources/yolo_model/yolo_training\u001B[0m\n",
      "Evaluating YOLO model metrics...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "evaluate_yolo_model_metrics() missing 1 required positional argument: 'ground_truth_boxes_dict'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[15], line 10\u001B[0m\n\u001B[1;32m      6\u001B[0m     evaluate_yolo_model_metrics(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(model_output_path, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myolo_training/weights/best.pt\u001B[39m\u001B[38;5;124m\"\u001B[39m), os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(test_output_path, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimages\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[1;32m      9\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYOLO training and evaluation completed.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 10\u001B[0m \u001B[43mtrain_model_and_eval\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[15], line 6\u001B[0m, in \u001B[0;36mtrain_model_and_eval\u001B[0;34m()\u001B[0m\n\u001B[1;32m      3\u001B[0m train_yolo_model(train_output_path, test_output_path, epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m80\u001B[39m, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m16\u001B[39m)\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEvaluating YOLO model metrics...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 6\u001B[0m \u001B[43mevaluate_yolo_model_metrics\u001B[49m\u001B[43m(\u001B[49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_output_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43myolo_training/weights/best.pt\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtest_output_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mimages\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYOLO training and evaluation completed.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mTypeError\u001B[0m: evaluate_yolo_model_metrics() missing 1 required positional argument: 'ground_truth_boxes_dict'"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T20:47:25.687702Z",
     "start_time": "2025-01-08T20:47:21.339334Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def parse_ground_truth_boxes(annotations_path):\n",
    "    \"\"\"\n",
    "    Parse ground truth bounding boxes from XML files into a dictionary.\n",
    "    :param annotations_path: Path to the annotations directory.\n",
    "    :return: Dictionary mapping image filenames to bounding boxes.\n",
    "    \"\"\"\n",
    "    ground_truth_boxes = {}\n",
    "    for annotation_file in os.listdir(annotations_path):\n",
    "        if annotation_file.endswith('.xml'):\n",
    "            annotation_path = os.path.join(annotations_path, annotation_file)\n",
    "            tree = ET.parse(annotation_path)\n",
    "            root = tree.getroot()\n",
    "\n",
    "            boxes = []\n",
    "            for obj in root.findall(\"object\"):\n",
    "                class_name = obj.find(\"name\").text\n",
    "                class_id = 0 if class_name == \"without_mask\" else 1  # Map class names to IDs\n",
    "\n",
    "                bndbox = obj.find(\"bndbox\")\n",
    "                xmin = int(bndbox.find(\"xmin\").text)\n",
    "                ymin = int(bndbox.find(\"ymin\").text)\n",
    "                xmax = int(bndbox.find(\"xmax\").text)\n",
    "                ymax = int(bndbox.find(\"ymax\").text)\n",
    "\n",
    "                boxes.append([xmin, ymin, xmax, ymax, class_id])\n",
    "\n",
    "            image_filename = root.find(\"filename\").text\n",
    "            ground_truth_boxes[image_filename] = boxes\n",
    "\n",
    "    return ground_truth_boxes\n",
    "ground_truth_boxes_dict = parse_ground_truth_boxes(annotations_path)\n",
    "evaluate_yolo_model_metrics(\n",
    "    os.path.join(model_output_path, \"yolo_training/weights/best.pt\"),\n",
    "    os.path.join(test_output_path, \"images\"),\n",
    "    ground_truth_boxes_dict\n",
    ")"
   ],
   "id": "3a6ab1459f7b747c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss196.png: 640x512 1 with_mask, 9.4ms\n",
      "Speed: 2.1ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processed maksssksksss196.png: Ground Truths=1, Predictions=1\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss765.png: 640x512 1 with_mask, 6.4ms\n",
      "Speed: 1.5ms preprocess, 6.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processed maksssksksss765.png: Ground Truths=1, Predictions=1\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss776.png: 448x640 2 with_masks, 10.1ms\n",
      "Speed: 2.0ms preprocess, 10.1ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed maksssksksss776.png: Ground Truths=2, Predictions=2\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss430.png: 480x640 1 without_mask, 2 with_masks, 9.0ms\n",
      "Speed: 1.6ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Skipping maksssksksss430.png: Ground Truths=2, Predictions=3\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss712.png: 640x512 1 with_mask, 9.3ms\n",
      "Speed: 1.9ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processed maksssksksss712.png: Ground Truths=1, Predictions=1\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss321.png: 352x640 1 without_mask, 1 with_mask, 6.5ms\n",
      "Speed: 1.3ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
      "Processed maksssksksss321.png: Ground Truths=2, Predictions=2\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss534.png: 448x640 2 without_masks, 11 with_masks, 9.3ms\n",
      "Speed: 2.1ms preprocess, 9.3ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Skipping maksssksksss534.png: Ground Truths=11, Predictions=13\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss354.png: 480x640 24 with_masks, 9.8ms\n",
      "Speed: 1.8ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Skipping maksssksksss354.png: Ground Truths=25, Predictions=24\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss451.png: 448x640 3 without_masks, 10 with_masks, 8.1ms\n",
      "Speed: 2.1ms preprocess, 8.1ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed maksssksksss451.png: Ground Truths=13, Predictions=13\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss395.png: 448x640 1 with_mask, 6.9ms\n",
      "Speed: 1.7ms preprocess, 6.9ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed maksssksksss395.png: Ground Truths=1, Predictions=1\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss90.png: 448x640 10 with_masks, 8.1ms\n",
      "Speed: 2.0ms preprocess, 8.1ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Skipping maksssksksss90.png: Ground Truths=8, Predictions=10\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss668.png: 640x512 1 with_mask, 6.5ms\n",
      "Speed: 1.6ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processed maksssksksss668.png: Ground Truths=1, Predictions=1\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss92.png: 448x640 1 without_mask, 7 with_masks, 6.6ms\n",
      "Speed: 1.3ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed maksssksksss92.png: Ground Truths=8, Predictions=8\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss849.png: 384x640 4 with_masks, 7.3ms\n",
      "Speed: 1.7ms preprocess, 7.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processed maksssksksss849.png: Ground Truths=4, Predictions=4\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss759.png: 448x640 2 without_masks, 2 with_masks, 6.9ms\n",
      "Speed: 1.5ms preprocess, 6.9ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Skipping maksssksksss759.png: Ground Truths=3, Predictions=4\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss605.png: 640x448 1 without_mask, 1 with_mask, 8.3ms\n",
      "Speed: 1.9ms preprocess, 8.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Skipping maksssksksss605.png: Ground Truths=1, Predictions=2\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss253.png: 480x640 3 without_masks, 7 with_masks, 10.1ms\n",
      "Speed: 2.8ms preprocess, 10.1ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed maksssksksss253.png: Ground Truths=10, Predictions=10\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss137.png: 640x640 4 without_masks, 3 with_masks, 8.5ms\n",
      "Speed: 2.1ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Skipping maksssksksss137.png: Ground Truths=6, Predictions=7\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss687.png: 640x512 1 with_mask, 6.7ms\n",
      "Speed: 1.6ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processed maksssksksss687.png: Ground Truths=1, Predictions=1\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss147.png: 416x640 1 without_mask, 3 with_masks, 8.6ms\n",
      "Speed: 1.7ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "Processed maksssksksss147.png: Ground Truths=4, Predictions=4\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss644.png: 640x512 1 with_mask, 7.2ms\n",
      "Speed: 2.3ms preprocess, 7.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processed maksssksksss644.png: Ground Truths=1, Predictions=1\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss574.png: 384x640 6 with_masks, 8.7ms\n",
      "Speed: 1.6ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processed maksssksksss574.png: Ground Truths=6, Predictions=6\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss781.png: 640x512 1 with_mask, 8.0ms\n",
      "Speed: 2.1ms preprocess, 8.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processed maksssksksss781.png: Ground Truths=1, Predictions=1\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss606.png: 448x640 1 without_mask, 3 with_masks, 6.1ms\n",
      "Speed: 1.4ms preprocess, 6.1ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Skipping maksssksksss606.png: Ground Truths=2, Predictions=4\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss307.png: 384x640 2 with_masks, 7.5ms\n",
      "Speed: 1.7ms preprocess, 7.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Skipping maksssksksss307.png: Ground Truths=3, Predictions=2\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss613.png: 448x640 3 without_masks, 6 with_masks, 8.6ms\n",
      "Speed: 1.6ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Skipping maksssksksss613.png: Ground Truths=10, Predictions=9\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss768.png: 384x640 7 with_masks, 6.0ms\n",
      "Speed: 1.2ms preprocess, 6.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Skipping maksssksksss768.png: Ground Truths=6, Predictions=7\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss851.png: 640x512 1 with_mask, 7.7ms\n",
      "Speed: 2.2ms preprocess, 7.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processed maksssksksss851.png: Ground Truths=1, Predictions=1\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss529.png: 384x640 1 without_mask, 5 with_masks, 7.8ms\n",
      "Speed: 1.5ms preprocess, 7.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Skipping maksssksksss529.png: Ground Truths=8, Predictions=6\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss491.png: 640x512 1 with_mask, 7.5ms\n",
      "Speed: 1.9ms preprocess, 7.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processed maksssksksss491.png: Ground Truths=1, Predictions=1\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss485.png: 640x512 1 with_mask, 7.1ms\n",
      "Speed: 2.2ms preprocess, 7.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processed maksssksksss485.png: Ground Truths=1, Predictions=1\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss472.png: 480x640 1 with_mask, 8.8ms\n",
      "Speed: 1.9ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed maksssksksss472.png: Ground Truths=1, Predictions=1\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss342.png: 416x640 2 without_masks, 12 with_masks, 6.1ms\n",
      "Speed: 1.2ms preprocess, 6.1ms inference, 0.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "Skipping maksssksksss342.png: Ground Truths=13, Predictions=14\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss279.png: 448x640 1 with_mask, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 0.9ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Skipping maksssksksss279.png: Ground Truths=3, Predictions=1\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss479.png: 640x512 1 with_mask, 6.9ms\n",
      "Speed: 1.9ms preprocess, 6.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processed maksssksksss479.png: Ground Truths=1, Predictions=1\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss60.png: 640x512 1 with_mask, 5.9ms\n",
      "Speed: 1.4ms preprocess, 5.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processed maksssksksss60.png: Ground Truths=1, Predictions=1\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss108.png: 384x640 1 without_mask, 7 with_masks, 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Skipping maksssksksss108.png: Ground Truths=5, Predictions=8\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss443.png: 640x512 1 without_mask, 6.0ms\n",
      "Speed: 1.4ms preprocess, 6.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processed maksssksksss443.png: Ground Truths=1, Predictions=1\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss771.png: 448x640 5 with_masks, 7.1ms\n",
      "Speed: 2.1ms preprocess, 7.1ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed maksssksksss771.png: Ground Truths=5, Predictions=5\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss678.png: 384x640 2 without_masks, 2 with_masks, 6.7ms\n",
      "Speed: 1.4ms preprocess, 6.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Skipping maksssksksss678.png: Ground Truths=2, Predictions=4\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss684.png: 448x640 2 without_masks, 3 with_masks, 8.6ms\n",
      "Speed: 2.5ms preprocess, 8.6ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed maksssksksss684.png: Ground Truths=5, Predictions=5\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss276.png: 640x544 1 with_mask, 7.6ms\n",
      "Speed: 1.9ms preprocess, 7.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Skipping maksssksksss276.png: Ground Truths=2, Predictions=1\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss96.png: 448x640 2 without_masks, 2 with_masks, 8.9ms\n",
      "Speed: 2.4ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed maksssksksss96.png: Ground Truths=4, Predictions=4\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss184.png: 352x640 12 with_masks, 9.7ms\n",
      "Speed: 1.7ms preprocess, 9.7ms inference, 1.7ms postprocess per image at shape (1, 3, 352, 640)\n",
      "Skipping maksssksksss184.png: Ground Truths=10, Predictions=12\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss659.png: 640x512 1 with_mask, 8.1ms\n",
      "Speed: 1.7ms preprocess, 8.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processed maksssksksss659.png: Ground Truths=1, Predictions=1\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss714.png: 480x640 4 with_masks, 8.9ms\n",
      "Speed: 1.5ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed maksssksksss714.png: Ground Truths=4, Predictions=4\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss509.png: 384x640 1 with_mask, 7.8ms\n",
      "Speed: 1.6ms preprocess, 7.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processed maksssksksss509.png: Ground Truths=1, Predictions=1\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss312.png: 640x480 4 with_masks, 8.0ms\n",
      "Speed: 1.9ms preprocess, 8.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Skipping maksssksksss312.png: Ground Truths=3, Predictions=4\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss66.png: 640x608 1 with_mask, 8.9ms\n",
      "Speed: 2.2ms preprocess, 8.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 608)\n",
      "Processed maksssksksss66.png: Ground Truths=1, Predictions=1\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss453.png: 480x640 14 without_masks, 7 with_masks, 9.9ms\n",
      "Speed: 1.6ms preprocess, 9.9ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Skipping maksssksksss453.png: Ground Truths=23, Predictions=21\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss100.png: 384x640 2 with_masks, 8.7ms\n",
      "Speed: 1.3ms preprocess, 8.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Skipping maksssksksss100.png: Ground Truths=3, Predictions=2\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss423.png: 384x640 14 with_masks, 7.8ms\n",
      "Speed: 1.5ms preprocess, 7.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Skipping maksssksksss423.png: Ground Truths=13, Predictions=14\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss336.png: 448x640 3 without_masks, 5 with_masks, 7.4ms\n",
      "Speed: 1.5ms preprocess, 7.4ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed maksssksksss336.png: Ground Truths=8, Predictions=8\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss382.png: 480x640 5 with_masks, 8.0ms\n",
      "Speed: 2.8ms preprocess, 8.0ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed maksssksksss382.png: Ground Truths=5, Predictions=5\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss69.png: 576x640 1 with_mask, 6.2ms\n",
      "Speed: 2.2ms preprocess, 6.2ms inference, 1.2ms postprocess per image at shape (1, 3, 576, 640)\n",
      "Processed maksssksksss69.png: Ground Truths=1, Predictions=1\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss494.png: 640x448 1 with_mask, 8.0ms\n",
      "Speed: 1.3ms preprocess, 8.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processed maksssksksss494.png: Ground Truths=1, Predictions=1\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss260.png: 480x640 56 with_masks, 5.8ms\n",
      "Speed: 2.4ms preprocess, 5.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Skipping maksssksksss260.png: Ground Truths=53, Predictions=56\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss663.png: 640x512 1 with_mask, 6.9ms\n",
      "Speed: 1.8ms preprocess, 6.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processed maksssksksss663.png: Ground Truths=1, Predictions=1\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss203.png: 384x640 5 with_masks, 7.1ms\n",
      "Speed: 1.8ms preprocess, 7.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Skipping maksssksksss203.png: Ground Truths=4, Predictions=5\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss109.png: 640x640 1 with_mask, 6.7ms\n",
      "Speed: 2.4ms preprocess, 6.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processed maksssksksss109.png: Ground Truths=1, Predictions=1\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss837.png: 640x512 1 without_mask, 7.3ms\n",
      "Speed: 1.9ms preprocess, 7.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processed maksssksksss837.png: Ground Truths=1, Predictions=1\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss733.png: 480x640 1 with_mask, 5.8ms\n",
      "Speed: 2.2ms preprocess, 5.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed maksssksksss733.png: Ground Truths=1, Predictions=1\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss581.png: 640x512 1 with_mask, 8.3ms\n",
      "Speed: 1.7ms preprocess, 8.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processed maksssksksss581.png: Ground Truths=1, Predictions=1\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss645.png: 640x512 1 with_mask, 6.9ms\n",
      "Speed: 1.6ms preprocess, 6.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processed maksssksksss645.png: Ground Truths=1, Predictions=1\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss426.png: 448x640 1 with_mask, 7.1ms\n",
      "Speed: 2.3ms preprocess, 7.1ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed maksssksksss426.png: Ground Truths=1, Predictions=1\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss558.png: 384x640 5 without_masks, 16 with_masks, 8.9ms\n",
      "Speed: 1.9ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Skipping maksssksksss558.png: Ground Truths=17, Predictions=21\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss168.png: 384x640 2 without_masks, 2 with_masks, 6.6ms\n",
      "Speed: 1.4ms preprocess, 6.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Skipping maksssksksss168.png: Ground Truths=5, Predictions=4\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss252.png: 448x640 1 with_mask, 8.5ms\n",
      "Speed: 1.7ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed maksssksksss252.png: Ground Truths=1, Predictions=1\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss319.png: 416x640 3 without_masks, 6 with_masks, 8.3ms\n",
      "Speed: 1.7ms preprocess, 8.3ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "Skipping maksssksksss319.png: Ground Truths=11, Predictions=9\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss134.png: 384x640 2 without_masks, 4 with_masks, 7.3ms\n",
      "Speed: 1.7ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Skipping maksssksksss134.png: Ground Truths=7, Predictions=6\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss361.png: 416x640 3 without_masks, 2 with_masks, 8.3ms\n",
      "Speed: 1.6ms preprocess, 8.3ms inference, 1.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "Skipping maksssksksss361.png: Ground Truths=3, Predictions=5\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss657.png: 448x640 6 without_masks, 6 with_masks, 7.8ms\n",
      "Speed: 1.5ms preprocess, 7.8ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Skipping maksssksksss657.png: Ground Truths=13, Predictions=12\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss511.png: 480x640 1 with_mask, 8.6ms\n",
      "Speed: 2.1ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed maksssksksss511.png: Ground Truths=1, Predictions=1\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss433.png: 640x512 1 with_mask, 8.5ms\n",
      "Speed: 1.8ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processed maksssksksss433.png: Ground Truths=1, Predictions=1\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss610.png: 352x640 3 with_masks, 9.4ms\n",
      "Speed: 1.2ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
      "Processed maksssksksss610.png: Ground Truths=3, Predictions=3\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss373.png: 448x640 2 without_masks, 11 with_masks, 8.1ms\n",
      "Speed: 2.1ms preprocess, 8.1ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed maksssksksss373.png: Ground Truths=13, Predictions=13\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss631.png: 352x640 11 with_masks, 7.2ms\n",
      "Speed: 1.4ms preprocess, 7.2ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
      "Processed maksssksksss631.png: Ground Truths=11, Predictions=11\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss841.png: 640x512 1 without_mask, 6.8ms\n",
      "Speed: 1.8ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processed maksssksksss841.png: Ground Truths=1, Predictions=1\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss741.png: 640x448 1 with_mask, 6.0ms\n",
      "Speed: 1.3ms preprocess, 6.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processed maksssksksss741.png: Ground Truths=1, Predictions=1\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss417.png: 640x512 1 with_mask, 8.6ms\n",
      "Speed: 1.7ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processed maksssksksss417.png: Ground Truths=1, Predictions=1\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss320.png: 384x640 1 without_mask, 3 with_masks, 7.3ms\n",
      "Speed: 1.5ms preprocess, 7.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processed maksssksksss320.png: Ground Truths=4, Predictions=4\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss376.png: 384x640 7 with_masks, 5.2ms\n",
      "Speed: 1.2ms preprocess, 5.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processed maksssksksss376.png: Ground Truths=7, Predictions=7\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss683.png: 640x480 1 with_mask, 5.6ms\n",
      "Speed: 2.2ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processed maksssksksss683.png: Ground Truths=1, Predictions=1\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss460.png: 448x640 2 without_masks, 8 with_masks, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Skipping maksssksksss460.png: Ground Truths=12, Predictions=10\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss392.png: 448x640 1 with_mask, 6.8ms\n",
      "Speed: 1.5ms preprocess, 6.8ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed maksssksksss392.png: Ground Truths=1, Predictions=1\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss215.png: 640x640 2 with_masks, 7.1ms\n",
      "Speed: 2.4ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processed maksssksksss215.png: Ground Truths=2, Predictions=2\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss807.png: 448x640 8 with_masks, 8.7ms\n",
      "Speed: 1.6ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Skipping maksssksksss807.png: Ground Truths=9, Predictions=8\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss107.png: 640x512 1 with_mask, 7.1ms\n",
      "Speed: 1.7ms preprocess, 7.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processed maksssksksss107.png: Ground Truths=1, Predictions=1\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss409.png: 640x512 1 with_mask, 5.6ms\n",
      "Speed: 1.5ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processed maksssksksss409.png: Ground Truths=1, Predictions=1\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss672.png: 480x640 7 without_masks, 6 with_masks, 8.4ms\n",
      "Speed: 1.5ms preprocess, 8.4ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Skipping maksssksksss672.png: Ground Truths=9, Predictions=13\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss518.png: 384x640 9 without_masks, 77 with_masks, 7.6ms\n",
      "Speed: 1.4ms preprocess, 7.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Skipping maksssksksss518.png: Ground Truths=83, Predictions=86\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss141.png: 448x640 2 with_masks, 8.1ms\n",
      "Speed: 1.6ms preprocess, 8.1ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed maksssksksss141.png: Ground Truths=2, Predictions=2\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss306.png: 640x512 1 with_mask, 7.1ms\n",
      "Speed: 2.1ms preprocess, 7.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processed maksssksksss306.png: Ground Truths=1, Predictions=1\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss693.png: 640x448 3 without_masks, 3 with_masks, 9.0ms\n",
      "Speed: 1.9ms preprocess, 9.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Skipping maksssksksss693.png: Ground Truths=2, Predictions=6\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss391.png: 448x640 1 without_mask, 4 with_masks, 6.9ms\n",
      "Speed: 2.5ms preprocess, 6.9ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Skipping maksssksksss391.png: Ground Truths=4, Predictions=5\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss21.png: 384x640 2 without_masks, 4 with_masks, 8.7ms\n",
      "Speed: 1.6ms preprocess, 8.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Skipping maksssksksss21.png: Ground Truths=5, Predictions=6\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss390.png: 480x640 6 with_masks, 8.4ms\n",
      "Speed: 1.7ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed maksssksksss390.png: Ground Truths=6, Predictions=6\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss401.png: 448x640 1 without_mask, 2 with_masks, 9.8ms\n",
      "Speed: 2.1ms preprocess, 9.8ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Skipping maksssksksss401.png: Ground Truths=4, Predictions=3\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss612.png: 480x640 1 with_mask, 8.5ms\n",
      "Speed: 1.6ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed maksssksksss612.png: Ground Truths=1, Predictions=1\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss240.png: 416x640 46 without_masks, 11 with_masks, 8.1ms\n",
      "Speed: 2.1ms preprocess, 8.1ms inference, 1.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "Skipping maksssksksss240.png: Ground Truths=61, Predictions=57\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss477.png: 448x640 6 without_masks, 7 with_masks, 6.4ms\n",
      "Speed: 1.4ms preprocess, 6.4ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed maksssksksss477.png: Ground Truths=13, Predictions=13\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss363.png: 320x640 6 with_masks, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Processed maksssksksss363.png: Ground Truths=6, Predictions=6\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss112.png: 640x448 1 with_mask, 6.5ms\n",
      "Speed: 1.6ms preprocess, 6.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processed maksssksksss112.png: Ground Truths=1, Predictions=1\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss330.png: 480x640 4 with_masks, 8.6ms\n",
      "Speed: 1.8ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed maksssksksss330.png: Ground Truths=4, Predictions=4\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss420.png: 640x512 1 without_mask, 7.1ms\n",
      "Speed: 2.0ms preprocess, 7.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processed maksssksksss420.png: Ground Truths=1, Predictions=1\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss752.png: 384x640 10 with_masks, 7.8ms\n",
      "Speed: 1.4ms preprocess, 7.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Skipping maksssksksss752.png: Ground Truths=11, Predictions=10\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss497.png: 640x512 1 with_mask, 8.2ms\n",
      "Speed: 2.0ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processed maksssksksss497.png: Ground Truths=1, Predictions=1\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss411.png: 448x640 1 without_mask, 8 with_masks, 7.9ms\n",
      "Speed: 2.0ms preprocess, 7.9ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Skipping maksssksksss411.png: Ground Truths=8, Predictions=9\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss604.png: 384x640 2 with_masks, 7.1ms\n",
      "Speed: 1.4ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processed maksssksksss604.png: Ground Truths=2, Predictions=2\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss551.png: 448x640 5 with_masks, 6.0ms\n",
      "Speed: 1.4ms preprocess, 6.0ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed maksssksksss551.png: Ground Truths=5, Predictions=5\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss416.png: 384x640 5 with_masks, 11.3ms\n",
      "Speed: 2.8ms preprocess, 11.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Skipping maksssksksss416.png: Ground Truths=4, Predictions=5\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss212.png: 640x448 1 with_mask, 6.8ms\n",
      "Speed: 1.3ms preprocess, 6.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processed maksssksksss212.png: Ground Truths=1, Predictions=1\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss549.png: 480x640 1 with_mask, 7.8ms\n",
      "Speed: 2.5ms preprocess, 7.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed maksssksksss549.png: Ground Truths=1, Predictions=1\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss331.png: 448x640 5 without_masks, 13 with_masks, 8.2ms\n",
      "Speed: 1.5ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Skipping maksssksksss331.png: Ground Truths=15, Predictions=18\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss611.png: 448x640 5 with_masks, 6.2ms\n",
      "Speed: 1.4ms preprocess, 6.2ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed maksssksksss611.png: Ground Truths=5, Predictions=5\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss698.png: 544x640 2 without_masks, 4 with_masks, 10.9ms\n",
      "Speed: 2.2ms preprocess, 10.9ms inference, 1.2ms postprocess per image at shape (1, 3, 544, 640)\n",
      "Skipping maksssksksss698.png: Ground Truths=7, Predictions=6\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss190.png: 480x640 1 with_mask, 8.2ms\n",
      "Speed: 1.7ms preprocess, 8.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed maksssksksss190.png: Ground Truths=1, Predictions=1\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss34.png: 448x640 2 without_masks, 6 with_masks, 5.8ms\n",
      "Speed: 1.3ms preprocess, 5.8ms inference, 0.9ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed maksssksksss34.png: Ground Truths=8, Predictions=8\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss469.png: 480x640 2 with_masks, 9.4ms\n",
      "Speed: 1.9ms preprocess, 9.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed maksssksksss469.png: Ground Truths=2, Predictions=2\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss709.png: 640x512 1 with_mask, 8.0ms\n",
      "Speed: 1.9ms preprocess, 8.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processed maksssksksss709.png: Ground Truths=1, Predictions=1\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss408.png: 384x640 1 without_mask, 8 with_masks, 8.7ms\n",
      "Speed: 1.5ms preprocess, 8.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Skipping maksssksksss408.png: Ground Truths=10, Predictions=9\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss520.png: 640x512 1 with_mask, 8.1ms\n",
      "Speed: 3.0ms preprocess, 8.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processed maksssksksss520.png: Ground Truths=1, Predictions=1\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss572.png: 384x640 1 without_mask, 5 with_masks, 7.1ms\n",
      "Speed: 1.4ms preprocess, 7.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processed maksssksksss572.png: Ground Truths=6, Predictions=6\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss115.png: 448x640 10 with_masks, 5.9ms\n",
      "Speed: 1.2ms preprocess, 5.9ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Skipping maksssksksss115.png: Ground Truths=9, Predictions=10\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss378.png: 320x640 2 with_masks, 8.2ms\n",
      "Speed: 1.4ms preprocess, 8.2ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Processed maksssksksss378.png: Ground Truths=2, Predictions=2\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss751.png: 448x640 1 without_mask, 3 with_masks, 6.5ms\n",
      "Speed: 1.4ms preprocess, 6.5ms inference, 0.9ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed maksssksksss751.png: Ground Truths=4, Predictions=4\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss674.png: 384x640 1 without_mask, 19 with_masks, 6.3ms\n",
      "Speed: 1.2ms preprocess, 6.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Skipping maksssksksss674.png: Ground Truths=18, Predictions=20\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss758.png: 448x640 6 with_masks, 7.6ms\n",
      "Speed: 1.6ms preprocess, 7.6ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Skipping maksssksksss758.png: Ground Truths=5, Predictions=6\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss694.png: 448x640 6 with_masks, 7.5ms\n",
      "Speed: 1.6ms preprocess, 7.5ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed maksssksksss694.png: Ground Truths=6, Predictions=6\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss658.png: 640x448 1 with_mask, 7.0ms\n",
      "Speed: 1.9ms preprocess, 7.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processed maksssksksss658.png: Ground Truths=1, Predictions=1\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss32.png: 384x640 2 with_masks, 7.9ms\n",
      "Speed: 1.3ms preprocess, 7.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processed maksssksksss32.png: Ground Truths=2, Predictions=2\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss819.png: 384x640 1 without_mask, 1 with_mask, 6.4ms\n",
      "Speed: 1.6ms preprocess, 6.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Skipping maksssksksss819.png: Ground Truths=1, Predictions=2\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss774.png: 384x640 3 with_masks, 6.7ms\n",
      "Speed: 1.2ms preprocess, 6.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processed maksssksksss774.png: Ground Truths=3, Predictions=3\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss829.png: 320x640 1 without_mask, 9 with_masks, 6.9ms\n",
      "Speed: 1.6ms preprocess, 6.9ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Skipping maksssksksss829.png: Ground Truths=12, Predictions=10\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss68.png: 640x512 1 without_mask, 7.6ms\n",
      "Speed: 2.3ms preprocess, 7.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processed maksssksksss68.png: Ground Truths=1, Predictions=1\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss490.png: 640x512 1 with_mask, 6.6ms\n",
      "Speed: 1.7ms preprocess, 6.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processed maksssksksss490.png: Ground Truths=1, Predictions=1\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss836.png: 512x640 5 with_masks, 9.6ms\n",
      "Speed: 2.2ms preprocess, 9.6ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Processed maksssksksss836.png: Ground Truths=5, Predictions=5\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss740.png: 448x640 2 with_masks, 8.5ms\n",
      "Speed: 1.9ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed maksssksksss740.png: Ground Truths=2, Predictions=2\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss502.png: 384x640 2 without_masks, 2 with_masks, 6.2ms\n",
      "Speed: 1.4ms preprocess, 6.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processed maksssksksss502.png: Ground Truths=4, Predictions=4\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss339.png: 640x640 1 with_mask, 9.1ms\n",
      "Speed: 2.2ms preprocess, 9.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processed maksssksksss339.png: Ground Truths=1, Predictions=1\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss237.png: 448x640 2 with_masks, 8.8ms\n",
      "Speed: 2.5ms preprocess, 8.8ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed maksssksksss237.png: Ground Truths=2, Predictions=2\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss721.png: 640x512 1 with_mask, 5.7ms\n",
      "Speed: 1.8ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processed maksssksksss721.png: Ground Truths=1, Predictions=1\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss764.png: 640x512 1 with_mask, 9.1ms\n",
      "Speed: 1.7ms preprocess, 9.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processed maksssksksss764.png: Ground Truths=1, Predictions=1\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss142.png: 480x640 1 with_mask, 7.1ms\n",
      "Speed: 1.5ms preprocess, 7.1ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed maksssksksss142.png: Ground Truths=1, Predictions=1\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss151.png: 320x640 9 with_masks, 9.0ms\n",
      "Speed: 1.2ms preprocess, 9.0ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Skipping maksssksksss151.png: Ground Truths=10, Predictions=9\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss322.png: 640x512 1 with_mask, 7.5ms\n",
      "Speed: 2.9ms preprocess, 7.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processed maksssksksss322.png: Ground Truths=1, Predictions=1\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss98.png: 448x640 4 with_masks, 6.1ms\n",
      "Speed: 2.3ms preprocess, 6.1ms inference, 0.9ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed maksssksksss98.png: Ground Truths=4, Predictions=4\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss177.png: 480x640 2 with_masks, 7.7ms\n",
      "Speed: 1.7ms preprocess, 7.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed maksssksksss177.png: Ground Truths=2, Predictions=2\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss71.png: 384x640 1 without_mask, 5 with_masks, 7.6ms\n",
      "Speed: 1.3ms preprocess, 7.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processed maksssksksss71.png: Ground Truths=6, Predictions=6\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss381.png: 512x640 1 without_mask, 4 with_masks, 7.3ms\n",
      "Speed: 1.6ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Skipping maksssksksss381.png: Ground Truths=6, Predictions=5\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss844.png: 384x640 2 with_masks, 7.7ms\n",
      "Speed: 1.8ms preprocess, 7.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processed maksssksksss844.png: Ground Truths=2, Predictions=2\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss213.png: 640x512 1 with_mask, 7.7ms\n",
      "Speed: 1.9ms preprocess, 7.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processed maksssksksss213.png: Ground Truths=1, Predictions=1\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss195.png: 640x640 1 with_mask, 6.1ms\n",
      "Speed: 1.8ms preprocess, 6.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processed maksssksksss195.png: Ground Truths=1, Predictions=1\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss699.png: 448x640 6 without_masks, 2 with_masks, 8.4ms\n",
      "Speed: 1.9ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Skipping maksssksksss699.png: Ground Truths=7, Predictions=8\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss310.png: 448x640 1 without_mask, 6 with_masks, 6.1ms\n",
      "Speed: 1.9ms preprocess, 6.1ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Skipping maksssksksss310.png: Ground Truths=6, Predictions=7\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss309.png: 640x448 1 with_mask, 8.0ms\n",
      "Speed: 1.4ms preprocess, 8.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processed maksssksksss309.png: Ground Truths=1, Predictions=1\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss11.png: 448x640 32 with_masks, 7.8ms\n",
      "Speed: 1.4ms preprocess, 7.8ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Skipping maksssksksss11.png: Ground Truths=16, Predictions=32\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss614.png: 640x512 1 with_mask, 6.7ms\n",
      "Speed: 2.5ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processed maksssksksss614.png: Ground Truths=1, Predictions=1\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss821.png: 448x640 2 without_masks, 1 with_mask, 8.5ms\n",
      "Speed: 1.7ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Skipping maksssksksss821.png: Ground Truths=2, Predictions=3\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss510.png: 448x640 4 with_masks, 7.7ms\n",
      "Speed: 2.9ms preprocess, 7.7ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed maksssksksss510.png: Ground Truths=4, Predictions=4\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss638.png: 448x640 2 with_masks, 6.7ms\n",
      "Speed: 1.6ms preprocess, 6.7ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed maksssksksss638.png: Ground Truths=2, Predictions=2\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss370.png: 640x512 1 without_mask, 7.3ms\n",
      "Speed: 2.0ms preprocess, 7.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processed maksssksksss370.png: Ground Truths=1, Predictions=1\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss535.png: 448x640 2 without_masks, 4 with_masks, 7.2ms\n",
      "Speed: 1.5ms preprocess, 7.2ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed maksssksksss535.png: Ground Truths=6, Predictions=6\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss204.png: 448x640 8 with_masks, 7.9ms\n",
      "Speed: 1.6ms preprocess, 7.9ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Skipping maksssksksss204.png: Ground Truths=7, Predictions=8\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss386.png: 448x640 6 with_masks, 7.0ms\n",
      "Speed: 2.1ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Skipping maksssksksss386.png: Ground Truths=9, Predictions=6\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss371.png: 384x640 1 with_mask, 8.2ms\n",
      "Speed: 1.5ms preprocess, 8.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processed maksssksksss371.png: Ground Truths=1, Predictions=1\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss466.png: 448x640 4 with_masks, 7.7ms\n",
      "Speed: 1.5ms preprocess, 7.7ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed maksssksksss466.png: Ground Truths=4, Predictions=4\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss429.png: 448x640 4 with_masks, 7.1ms\n",
      "Speed: 1.5ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed maksssksksss429.png: Ground Truths=4, Predictions=4\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss601.png: 640x512 1 with_mask, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processed maksssksksss601.png: Ground Truths=1, Predictions=1\n",
      "\n",
      "image 1/1 /home/djentci/Desktop/comp_vision_project/src/../resources/yolo_test/images/maksssksksss80.png: 384x640 1 with_mask, 7.7ms\n",
      "Speed: 1.1ms preprocess, 7.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processed maksssksksss80.png: Ground Truths=1, Predictions=1\n",
      "\n",
      "Evaluation Metrics:\n",
      "Precision: 0.84\n",
      "Recall: 0.84\n",
      "F1 Score: 0.84\n",
      "Mean IoU: 0.00\n",
      "Mean Confidence: 0.82\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T20:51:32.616754Z",
     "start_time": "2025-01-08T20:51:32.614894Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "59fcde37debb2945",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T20:51:26.456917Z",
     "start_time": "2025-01-08T20:51:26.454771Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "d691647673f51f40",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a0ac969335a4ed99"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
